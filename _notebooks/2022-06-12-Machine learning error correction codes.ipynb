{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [],
    "toc-hr-collapsed": true
   },
   "source": [
    "# Machine learning error correction codes\n",
    "> Sweeping conceptual difficulties under the rug with a black-box approach \n",
    "- toc: true \n",
    "- badges: true\n",
    "- comments: true\n",
    "- categories: [QML, QEC]\n",
    "- image: images/slide.png"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#collapse\n",
    "\n",
    "from collections import namedtuple\n",
    "from functools import reduce\n",
    "from mynimize import *\n",
    "from jax.scipy.linalg import                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                expm\n",
    "from jax import random\n",
    "from scipy.stats import unitary_group"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classical repetition code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following 99% of error correction tutorials I will start with the classical repetition code. And you know what, I do not even feel guilty, this is a great time-tested warm up. So, we are sending a classical bit along a noisy channel and it is flipped with a probability $p$. The error probability can be suppressed if we are willing to send more bits. Namely, instead of sending `0` we send `000`, instead of `1` we send `111`. This is called _encoding_, we encoded a single _logical_ bit into several _physical_ bits. Due to errors, the message `000` can be corrupted in several ways:\n",
    "1. `000` : no corruption, with probability $(1-p)^3$\n",
    "2. `100`, `010`, `001`: single corrupted bit, with probability $3 p(1-p)^2$\n",
    "3. `110`, `011`, `101`: two corrupted bits, with probability $3 p^2(1-p)$\n",
    "4. `111`: all bits flipped, with probability $p^3$\n",
    "\n",
    "Same holds for the `111` message.\n",
    "\n",
    "Now, if the receiver sees any message except `000` or `111` he knows there was an error somewhere. He can try to fix the error by taking a majority vote, e.g. he assumes that `100` means `0` while `101` means `1`. If the single-bit errors are much more likely than two-bit or three-bit errors, this _decoding_ strategy works. More precisely, it succeeds in cases (1) and (2) but fails in cases (3) and (4). The overall success probability is therefore $(1-p)^3+3p(1-p)^2$ and for $p>1/2$ it is in fact greater than $1-p$, the success probability of the unencoded message."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conceptual difficulties with QECC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now instead of sending a classical bit we want to send a qubit, also subject to noise. Can we use a similar strategy to protect the quantum bit? Textbooks often mention several apparent problems that make the quantum case sufficiently different from the classical.\n",
    "\n",
    "1. Qubit states are continuous. Instead of sending just `0` or `1` we need to be able to send an arbitrary superposition $|\\psi\\rangle=\\alpha|0\\rangle+\\beta|1\\rangle$.\n",
    "2. As a consequence, errors are also continuous. For example, instead of a full bit flip $X$ we can have 'just a bit' of a bit flip $R_X(\\theta)=\\cos(\\theta/2)-i X \\sin(\\theta/2)$ with very small $\\theta$. There are also additional error types with no classical counterparts, such as the phase flip error $Z$. General single-qubit unitary error is a linear combination $U=\\alpha_0+\\alpha_1 X+\\alpha_2 Y+\\alpha_3 Z$.\n",
    "3. Quantum states can not be cloned. This means that for an unknown quantum state $|\\psi\\rangle$ we can not construct and transmit e.g. $|\\psi\\rangle\\otimes|\\psi\\rangle\\otimes|\\psi\\rangle$ as a plain generalization of the repetition code, although that would definitely help. \n",
    "4. When the message is received, we need to look at it to decide if there was an error an choose a correction. But looking at the quantum states can break the coherence that we were looking to preserve.\n",
    "\n",
    "We now know that all these issues can be elegantly resolved and the the modern theory of error correction is rich and beautiful. My personal agenda for this small project was to see how far can one go with a black-box approach, sweeping all conceptual problems under the rug. The main two assumptions are\n",
    "- We need to use several physical qubits to safeguard a single logical qubit.\n",
    "- We only try to protect against single-qubit errors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine learning QECC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is an architecture that I have in mind.\n",
    "\n",
    "<img src=\"myimages/ecc_training/arch.svg\" alt=\"Drawing\" style=\"width: 800px;\"/>\n",
    "\n",
    "First, we embed a logical qubit into $n$ physical ones. I will do this in the simplest possible way $|\\psi\\rangle \\to |\\psi\\rangle\\otimes |0\\rangle^{n-1}$, i.e. assuming that the first physical qubit is the logical state to be transmitted while other physical qubits are initialized in $|0\\rangle$ states. The initial embedding is in fact irrelevant, because after that I allow for an arbitrary encoding transformation $U_{encoding}$. It is only required to be unitary. The encoding stage does the heavy lifting, and the encoding unitary is the main variable to be optimized. After that we add an error layer, which can consist of arbitrary single-qubit unitary errors. Then goes the decoding layer, which we will trust to recover the information about the logical qubit. I will assume that the decoding layer is also a unitary. At the final step, the physical qubit state must somehow be projected onto the single-qubit state which will be our final, received and corrected state.\n",
    "\n",
    "\n",
    "If you are familiar with quantum error correction, the assumption that decoding is a unitary operation and hence makes no explicit reference to syndrome measurements and things of that sort may look suspicious. We'll see that it works, and make some comments afterwards."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Design choices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Projecting the final state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are still details to be filled in. One is to specify how to get a single-qubit logical state from the final state of the physical qubits. Similarly to the embedding step, I will assume that the relevant information is contained exclusively in the first physical qubit. Then, successful error correction implies that the first physical qubit is unentangled with the others after the decoding step and has the same state it had before the encoding. \n",
    "\n",
    "$$|\\psi\\rangle\\otimes |0\\rangle^{n-1} \\to \\text{Encoding+Error+Decoding} \\to |\\psi\\rangle\\otimes |e\\rangle_{n-1}$$\n",
    "\n",
    "Note that the rest of the physical qubits will end up in different states $|e\\rangle_{n-1}$ depending on the error that have been corrected. Requiring that the final state is $|\\psi\\rangle\\otimes |0\\rangle^{(n-1)}$ regardless of the error is too strong and can not be satisfied for any interesting set of errors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dealing with continuum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, how do we deal with the continuum of states and errors? I guess that a truly black-box approach would be to generate a large set of initial states and single-qubit errors and train the model using all this data. If successful, check on the test data to exclude overfitting. I'm sure that would work, but here I will take a shortcut and exploit the linearity of the whole construction. Denote by $U(E)$ the full unitary process that an initial state goes trough for error $E$.\n",
    "\n",
    "$$U(E)=U_{decoding}\\,\\, U_{error}(E) \\,\\, U_{encoding} \\ .$$\n",
    "\n",
    "For given initial state $|\\psi\\rangle=\\alpha |0\\rangle+\\beta |1\\rangle$ and a fixed error $E$, the final state is fixed by the action on $|0\\rangle$ and $|1\\rangle$ states\n",
    "\n",
    "$$|\\psi\\rangle\\otimes |0\\rangle^{n-1}=\\alpha\\,\\, U(E) |0\\rangle\\otimes|0\\rangle^{n-1}+\\beta\\,\\, U(E)|1\\rangle\\otimes|0\\rangle^{n-1} \\ .$$\n",
    "\n",
    "Similarly, if we can correct errors corresponding to $X, Y$ and $Z$ unitaries on a given qubit, we will be able to correct an arbitrary linear combination of them, which is unitary. Indeed, say we can correct both $X$ and $Y$ errors\n",
    "\\begin{align*}\n",
    "|\\psi\\rangle\\otimes |0\\rangle^{n-1}\\to U(X) \\to |\\psi\\rangle\\otimes |x\\rangle_{n-1} \\ ,\\\\\n",
    "|\\psi\\rangle\\otimes |0\\rangle^{n-1}\\to U(Y) \\to |\\psi\\rangle\\otimes |y\\rangle_{n-1} \\ .\n",
    "\\end{align*}\n",
    "Then their unitary linear combination will also be corrected in a sence that the state of the first physical qubit is the original encoded state\n",
    "\\begin{align*}\n",
    "|\\psi\\rangle\\otimes |0\\rangle^{n-1}\\to U(aX+bY) \\to |\\psi\\rangle\\otimes\\left(a|x\\rangle_{n-1}+b|y\\rangle_{n-1}\\right) \\ .\n",
    "\\end{align*}\n",
    "In fact, correcting $X,Y$ and $Z$ errors on any of the qubits is sufficient to correct their arbitrary linear combination, including non-unitary ones and those acting on different qubits. More on that later."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is a code that implements the model. I do no use any quantum framework and deal with unitary matrices directly. That requires making a few tensor products here and there, but nothing cumbersome. I include the code right below in order to make this notebook/post self-contained, but do not go into detailed explanations. Here are several technical highlights though.\n",
    "- I use [JAX](https://jax.readthedocs.io/en/latest/#) as a numerical optimization backend. This why all the `jnp`s instead of `np`s.\n",
    "- I take a very low-key approach to optimization over unitary matrices, parametrizing them by Hermitian matrices $U=e^{i H}$. Basis in Hermitian matrices can be chosen to consist of $e_{ii}, e_{ij}+e_{ji}, i(e_{ij}-e_{ji})$. where $e_{ij}$ is a matrix with all elements except of one being zero. Matrix exponentiation is an expensive procedure and to scale the code to more qubits a better parametrization of the unitary group is required, e.g. as done here [QGOPT](https://github.com/LuchnikovI/QGOpt).\n",
    "- I choose the loss associated with an error correction process $U(E)$ in the following way. Let $|\\Psi_0\\rangle$ be the image of $|0\\rangle$ and $|\\Psi_1\\rangle$ of $|1\\rangle$\n",
    "$$|\\Psi_0\\rangle=U(E)|0\\rangle\\otimes |0\\rangle^{n-1},\\quad |\\Psi_1\\rangle=U(E)|1\\rangle\\otimes |0\\rangle^{n-1}\\ \\ . $$\n",
    "The loss is\n",
    "$$L(E) = 2-L_Z-L_X, \\qquad L_Z=\\langle \\Psi_0|Z_1|\\Psi_0\\rangle, \\qquad L_X=\\operatorname{Re} \\langle \\Psi_0|X_1|\\Psi_1\\rangle \\ .$$\n",
    "The term $L_Z$ is maximal $L_Z=1$ when $|\\Psi_0\\rangle=|0\\rangle \\otimes |e\\rangle_{n}$, i.e. when the $|0\\rangle$ state of the first physical qubit is preserved by the error correction. If $|0\\rangle$ is mapped to a mixed state or to a pure state different from $|0\\rangle$ we have $L_Z<1$. The term $L_X$ is maximal when the $|\\Psi_1\\rangle=X_1 |\\Psi_0\\rangle$. If $|0\\rangle\\otimes|0\\rangle^{n-1}\\to|0\\rangle \\otimes |e\\rangle_{n}$, this  condition implies that $|1\\rangle\\otimes|0\\rangle^{n-1} \\to |1\\rangle \\otimes |e\\rangle_{n}$. By linearity,  this is sufficient for an arbitray input state to be corrected when subject to this error.\n",
    "- The total loss is the sum of individual losses over all $X, Y, Z$ errors acting on each qubit\n",
    "$$L(E)=\\sum_{i=1}^{n}\\sum_{\\sigma=X,Y,Z} L(\\sigma_i) \\ .$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)\n"
     ]
    }
   ],
   "source": [
    "# Pauli matrices.\n",
    "x_mat = jnp.array([[0, 1],\n",
    "                   [1, 0]])\n",
    "\n",
    "y_mat = jnp.array([[0, -1j],\n",
    "                   [1j, 0]], dtype=jnp.complex64)\n",
    "\n",
    "z_mat = jnp.array([[1, 0],\n",
    "                   [0, -1]])\n",
    "\n",
    "pauli = (jnp.identity(2), x_mat, y_mat, z_mat)\n",
    "\n",
    "\n",
    "# Parametrized unitary matrices.\n",
    "class UnitaryLayer:\n",
    "    def __init__(self, num_qubits):\n",
    "        self.num_qubits = num_qubits\n",
    "        self.num_params = 4**num_qubits\n",
    "    \n",
    "    @staticmethod\n",
    "    def hermitian_basis(num_qubits):\n",
    "        d = 2**num_qubits\n",
    "        diag_basis = [jnp.zeros((d, d), dtype=jnp.complex64).at[i, i].set(1) for i in range(d)]\n",
    "        off_diag_real_basis = [jnp.zeros((d, d), dtype=jnp.complex64).at[i, j].set(1).at[j, i].set(1) for i in range(d) for j in range(i)]\n",
    "        off_diag_im_basis = [jnp.zeros((d, d), dtype=jnp.complex64).at[i, j].set(1j).at[j, i].set(-1j) for i in range(d) for j in range(i)]\n",
    "        return jnp.array(diag_basis+off_diag_real_basis+off_diag_im_basis)\n",
    "    \n",
    "    def unitary(self, params):\n",
    "        generator = jnp.tensordot(self.hermitian_basis(self.num_qubits), params, axes=((0, ), (0, )))\n",
    "        return expm(1j*generator)\n",
    "    \n",
    "\n",
    "# Matrices corresponding individual single-qubit errors.    \n",
    "class ErrorLayer:\n",
    "    def __init__(self, num_qubits, errors=pauli):\n",
    "        self.num_qubits = num_qubits\n",
    "        self.errors = errors\n",
    "    \n",
    "    def unitary(self, q, e):\n",
    "        error_list = [self.errors[e] if i==q else jnp.identity(2) for i in range(self.num_qubits)]\n",
    "        return reduce(jnp.kron, error_list)\n",
    "        \n",
    "    def all_error_unitaries(self):\n",
    "        single_error_unitaries = [self.unitary(q, e) for q in range(self.num_qubits) for e in range(len(self.errors))]\n",
    "        id_error = jnp.identity(2**self.num_qubits)\n",
    "        return jnp.array([id_error]+single_error_unitaries)\n",
    "\n",
    "# Model parameters as a namedtuple.    \n",
    "ecc_params = namedtuple('ECCparams', ['encoding_params', 'decoding_params'])\n",
    "\n",
    "class ECCmodel:\n",
    "    def __init__(self, num_qubits, error_layer, params=None):\n",
    "        self.num_qubits = num_qubits\n",
    "        self.error_layer = error_layer\n",
    "        self.encoding_layer = UnitaryLayer(num_qubits)\n",
    "        self.decoding_layer = UnitaryLayer(num_qubits)\n",
    "        self.params = params\n",
    "    \n",
    "    @staticmethod\n",
    "    def embed(initial_state, num_qubits):\n",
    "        \"\"\"Take |psi> and output |psi>|0,0,0, ...> \"\"\"\n",
    "        return jnp.kron(initial_state, jnp.zeros(2**(num_qubits-1)).at[0].set(1))\n",
    "    \n",
    "    \n",
    "    def final_state(self, initial_state, encoding_unitary, decoding_unitary, error_unitary):\n",
    "        s = decoding_unitary @ error_unitary @ encoding_unitary @ initial_state\n",
    "        return s\n",
    "    \n",
    "    def loss(self, params, error_unitary):\n",
    "        encoding_unitary = self.encoding_layer.unitary(params.encoding_params)\n",
    "        decoding_unitary = self.decoding_layer.unitary(params.decoding_params)\n",
    "        \n",
    "        final_states = []\n",
    "        for initial_state_1q in [[1,0], [0,1]]:\n",
    "            initial_state = self.embed(jnp.array(initial_state_1q, dtype=jnp.complex64), self.num_qubits)\n",
    "            final_state = self.final_state(initial_state, encoding_unitary, decoding_unitary, error_unitary)            \n",
    "            final_states.append(final_state)\n",
    "        \n",
    "        Psi_0, Psi_1 = final_states\n",
    "        \n",
    "        X1 = reduce(jnp.kron, [x_mat]+[jnp.identity(2)]*(self.num_qubits-1))\n",
    "        Z1 = reduce(jnp.kron, [z_mat]+[jnp.identity(2)]*(self.num_qubits-1))\n",
    "        \n",
    "        Z_avg = jnp.real(Psi_0.conj() @ Z1 @ Psi_0).sum()\n",
    "        X_off_diag = (Psi_0.conj() @ X1 @ Psi_1).sum()\n",
    "        return 2-Z_avg-jnp.real(X_off_diag)\n",
    "    \n",
    "    \n",
    "    def train(self, opt_options=OptOptions(num_iterations=1000)):\n",
    "\n",
    "        error_unitaries = self.error_layer.all_error_unitaries()\n",
    "        \n",
    "        def loss(params):\n",
    "            losses = vmap(lambda error_u: self.loss(params, error_u))(error_unitaries)\n",
    "            \n",
    "            return losses.sum()/len(error_unitaries)\n",
    "        \n",
    "        initial_params = random.uniform(random.PRNGKey(opt_options.random_seed), shape=(2, self.encoding_layer.num_params))\n",
    "        initial_params = [ecc_params(initial_params[0], initial_params[1])]\n",
    "        \n",
    "        # `mynimize` is just my custom optimization routine with a JAX backend. \n",
    "        results = mynimize(loss, initial_params, opt_options)        \n",
    "        self.params = results.best_result.best_params\n",
    "        return results.best_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quantum repetition code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is well known that with three physical qubits one can protect a logical qubit from $X$ erorrs. Let's see if our model can do that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 14.7 s, sys: 88.7 ms, total: 14.8 s\n",
      "Wall time: 14.8 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Loss history')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "num_qubits = 3\n",
    "error_layer = ErrorLayer(num_qubits, errors=[x_mat])\n",
    "\n",
    "model = ECCmodel(num_qubits, error_layer)\n",
    "result = model.train(OptOptions(num_iterations=1000))\n",
    "\n",
    "result.plot_loss_history();\n",
    "plt.xlabel('Iteration');\n",
    "plt.title('Loss history');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OK, the optimization is clearly successfull. Of course there is always a chance that there are mistakes in the code or in the definition of the loss function itself. I will give a more thorough verification for the 5-qubit code later. By modifying and re-running the cell above you can also do some simple sanity checks -- see if the same results can be achieved with fewer qubits (`num_qubits`$\\to$2) or if more errors can be corrected (`errors`$\\to$`[x_mat, y_mat]`). Neither works, of course."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Standard description of the quantum repetition code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have seen that a black-box approach works (you are welcome to challenge this claim, of course) it is instructive to revisit the usual construction of the error correcting codes. Here is how the quantum repetition code, which is able to correct $X$ errors, works. Encoding is done as follows\n",
    "\n",
    "$$|\\psi\\rangle=\\alpha|0\\rangle+\\beta|1\\rangle\\to \\alpha |000\\rangle+\\beta|111\\rangle \\ .$$\n",
    "\n",
    "This does not violate the no-cloning theorem because the new state is not $|\\psi\\rangle\\otimes|\\psi\\rangle\\otimes|\\psi\\rangle$. Coefficients $\\alpha$ and $\\beta$, which define the state, are not copied. This encoding can be done with the following circuit \n",
    "\n",
    "<img src=\"myimages/ecc_training/ghz.png\" alt=\"Drawing\" style=\"width: 150px;\"/>\n",
    "\n",
    "Now say there was an $X$ error acting on the first qubit during the transmission\n",
    "$$\\alpha |000\\rangle+\\beta|111\\rangle\\to X_1 \\to \\alpha |100\\rangle+\\beta|011\\rangle$$\n",
    "Can we detect an correct it? The problem is that measuring any of the qubits individually destroys their coherent superposition. A workaround is to make collective measurements $Z_1Z_2$ and $Z_1Z_3$, known as parity checks. Both terms in the corrupted decomposition have the same eigenvalues and hence coherence is preserved. Parity checks allow to identify qubit 1 as corrupted, and correct the error by applying $X_1$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Can we do without a measurment?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Measuments and post-selected correction operators were not part of our model, where the decoder is unitary. Is there something wrong with our approach, or measurements are not strictly necessary? I do think they aren't, but you would not be able to tell from most of the introductory literature. To illustrate the situation for the repetition code, I came up with the following unitary circuit, whihc can correct/decode any single $X$ error in the repetition code\n",
    "\n",
    "<img src=\"myimages/ecc_training/dec.png\" alt=\"Drawing\" style=\"width: 200px;\"/>\n",
    "\n",
    "It is straightfowrad to check that it transforms vectors with single $X$ errors as follows.\n",
    "\\begin{align*}\n",
    "I_{}:\\quad |000\\rangle\\to |000\\rangle,\\quad |111\\rangle\\to |100\\rangle\\\\\n",
    "X_1:\\quad|100\\rangle\\to |011\\rangle,\\quad |011\\rangle\\to |111\\rangle\\\\\n",
    "X_2:\\quad|010\\rangle\\to |101\\rangle,\\quad |010\\rangle\\to |110\\rangle\\\\\n",
    "X_3:\\quad|001\\rangle\\to |001\\rangle,\\quad |110\\rangle\\to |101\\rangle\\\\\n",
    "\\end{align*}\n",
    "Improtant things to note here are that the first qubit value becomes the majority vote, while two other qubit registers agree within the same line. I do not claim that our numerica optimization above discover exactly this circuit and or the repetition encoding, but it must be something equivalent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5 qubit code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The smallest amount of physical qubits that can correct against arbitrary single-qubit errors is known to be 5. Let me sketch a proof. Please! No, it's not needed to make my points, I just like it a lot. OK? Great! \n",
    "\n",
    "If a code can correct an arbitrary single-qubit error, it can also recover from the loss of two qubits.\n",
    "If we'd have an ECC with just four qubits, we could separate them into two groups 4=2+2. Each group could recover the encoded state, which produces two copies of it. This violates the no-cloning theorem! Lowering the number of qubits does not help, of course.\n",
    "\n",
    "OK, let's train the model on with 5 physical qubits and the error operators that span all single-qubit errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 22s, sys: 1.01 s, total: 2min 23s\n",
      "Wall time: 2min 21s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Loss history')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "num_qubits = 5\n",
    "error_layer = ErrorLayer(num_qubits, errors=[x_mat, y_mat, z_mat])\n",
    "\n",
    "model = ECCmodel(num_qubits, error_layer)\n",
    "result = model.train(OptOptions(num_iterations=1000))\n",
    "\n",
    "result.plot_loss_history();\n",
    "plt.xlabel('Iteration');\n",
    "plt.title('Loss history');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The loss function indicates that our model learns 5-qubit ECC. You may want to check that it does not work with fewer qubits, e.g. `num_qubits`$\\to$4. Another empirical observation is that if the model is trained on $X$ and $Z$ errors only, it will be able to correct $Y$ errors as well (passes verification below). This does not seem to be guarantied in general, as [counter-examples](https://quantumcomputing.stackexchange.com/questions/26846/if-a-quantum-error-correcting-code-corrects-both-x-and-z-errors-will-it-be) exist."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Verification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To convince you and myself that the loss plot above does reflect learning a genuine ECC here I will carry an independent check. First let me note that the way errors enter in the model we trained is not completely general. The most general evolution of the initial state under an interaction with an environment is described by a quantum channel\n",
    "\n",
    "$$|\\psi\\rangle\\to \\rho = \\operatorname{Tr}_{n-1}\\sum {M_a}|\\Psi\\rangle\\langle\\Psi|M_a^\\dagger,\\qquad |\\Psi\\rangle=|\\psi\\rangle\\otimes |0\\rangle^{n-1} .$$\n",
    "\n",
    "Here $\\rho$ is the final density matrix of the first physical qubit, which by our assumption corresponds to the logical qubit after error correction process. The partial trace is taken with respect to the other physical qubits. Matrices $M_a$ are called Kraus operators and could be thought of as a combination\n",
    "$$M_a = U_{decoding} E_a U_{encoding} \\ .$$\n",
    "We trained our model on cases where the error part $E_a$ in each Kraus operator $M_a$ is a single Pauli operator acting on some qubit, e.g. $E_a=X_2$. A general single-qubit error corresponds to each $E_a$ being a linear combination of single-qubit unitaries\n",
    "$$E_a=\\sum_{i=1}^{n} c_{ai} U_i.$$\n",
    "For example, one of them could be something like $E_1 = c_{11}(0.13 X_1+2.7 Y_1)+c_{12} Z_2 + c_{13} (Y_1-0.55 Z_1)$. Kraus operators are not required to be unitary, but only to satisfy the completeness relation $\\sum M_a^\\dagger M_a=1$. Our model was trained so that $M_a |\\Psi\\rangle=|\\psi\\rangle \\otimes |\\text{some state}\\rangle$ when $M_a$ only contains Pauli errors acting on a single qubit. However, this equation extends to arbitrary single-qubit errors by linearity.\n",
    "\n",
    "To perform an independent check I generate a bunch of initial states and generic single-qubit errors $E_a$. I will restrict to channels with single (non-normalized) Kraus operators for simplicity. If (normalized) density matrices\n",
    "$$ \\rho_a=\\frac{M_a|\\Psi\\rangle\\langle\\Psi|M_a^\\dagger}{\\langle \\Psi|M_a^\\dagger M_a|\\Psi\\rangle} $$\n",
    "reproduce the correlators of the original state for any $M_a$, they surely do for any sum over $M_a$. Thus, I will check that\n",
    "\n",
    "$$\\langle\\psi|X|\\psi\\rangle=\\operatorname{tr}\\rho_a X,\\quad \\langle\\psi|Y|\\psi\\rangle=\\operatorname{tr}\\rho_a Y,\\quad \\langle\\psi|Z|\\psi\\rangle=\\operatorname{tr}\\rho_a Z .$$\n",
    "\n",
    "Thus, we'll do full state tomography on a single qubit. This of course should be equivalent to the loss function we used during training, but I think reformulation is useful as an additional consistency check."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random seed, JAX-style\n",
    "key, *keys = random.split(random.PRNGKey(0), 3)\n",
    "\n",
    "# Sample sizes.\n",
    "num_qubits = model.num_qubits\n",
    "num_initial_states = 100\n",
    "num_errors = 100\n",
    "\n",
    "# Initial states, drawn at random and normalized.\n",
    "\n",
    "initial_states = random.uniform(keys[0], shape=(2, num_initial_states, 2)) # 2x real components\n",
    "initial_states = initial_states[0]+1j*initial_states[1] # combine into 1x complext components\n",
    "\n",
    "def norm_state(s):\n",
    "    return jnp.sqrt(jnp.real(s.conj()*s).sum())\n",
    "\n",
    "norms = [norm_state(s) for s in initial_states]\n",
    "initial_states = [s/norm_state(s) for s in initial_states]\n",
    "\n",
    "### Defining random linear combinations of single-qubits errors is a bit cumbersome, but purely technical.\n",
    "\n",
    "# Random single-qubit errors.\n",
    "random_1q_unitaries = unitary_group.rvs(2, size=num_errors*num_qubits).reshape(num_errors, num_qubits, 2, 2)\n",
    "random_coefficients = random.uniform(keys[1], (num_errors, num_qubits))\n",
    "\n",
    "\n",
    "def error_at_position(error_u, i, num_qubits):\n",
    "    \"\"\"Takes U and returns tensor product 1 x 1 x ... U x 1 ... x 1 with U at position i.\"\"\"\n",
    "    ops = [jnp.identity(2)]*num_qubits\n",
    "    ops[i] = error_u\n",
    "    return reduce(jnp.kron, ops)\n",
    "\n",
    "def make_error_operator(errors, coeffs):   \n",
    "    \"\"\"Takes a list of 1q errors and puts error 1 on qubit 1, error 2 on qubit 2, etc, then takes their liner combination.\"\"\"\n",
    "    num_qubits = len(errors)\n",
    "    full_errors = [error_at_position(u, i, num_qubits) for i, u in enumerate(errors)]\n",
    "    \n",
    "    return sum([u*c for u, c in zip(full_errors, coeffs)])\n",
    "\n",
    "errors = [make_error_operator(errors, coeffs) for errors, coeffs in zip(random_1q_unitaries, random_coefficients)]\n",
    "errors = jnp.array(errors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So finally we have a bunch of initial states and general (non-unitary) single-qubit error operators. Let's see directly the the model is able to correct them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DeviceArray(4.3243367e-07, dtype=float32)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = model.params\n",
    "\n",
    "u_encoding = model.encoding_layer.unitary(params.encoding_params)\n",
    "u_decoding = model.decoding_layer.unitary(params.decoding_params)\n",
    "\n",
    "def density_matrix(s):\n",
    "    \"\"\"Density matrix of the first qubit.\"\"\"\n",
    "    rho_full = jnp.outer(s, s.conj())\n",
    "    \n",
    "\n",
    "def tomography_loss(initial_state, error_u):\n",
    "    final_state = u_decoding @ error_u @ u_encoding @ ECCmodel.embed(initial_state, num_qubits)\n",
    "\n",
    "    pauli_averages_initial = [(initial_state.conj() @ p @ initial_state).sum() for p in [x_mat, y_mat, z_mat]]\n",
    "    pauli_averages_final = [(final_state.conj() @ jnp.kron(p, jnp.identity(2**(num_qubits-1))) @ final_state).sum() for p in pauli[1:]]\n",
    "    \n",
    "    total = sum([(avg_i - avg_f)**2 for avg_i, avg_f in zip(pauli_averages_initial, pauli_averages_final)])\n",
    "    return jnp.real(total)\n",
    "\n",
    "\n",
    "losses = [tomography_loss(s, u) for s in initial_states for u in errors]\n",
    "sum(losses)/len(losses)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
